{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b3-l8YQPlewV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SimpleNeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.2):\n",
        "        # Initialize weights (CHANGED)\n",
        "        self.W1 = np.array([\n",
        "            [0.2, -0.4],\n",
        "            [0.6,  0.3],\n",
        "            [-0.1, 0.5]\n",
        "        ])\n",
        "        print(f\"Initialized W1:\\n{self.W1}\")\n",
        "\n",
        "        self.W2 = np.array([\n",
        "            [0.4],\n",
        "            [-0.7]\n",
        "        ])\n",
        "        print(f\"Initialized W2:\\n{self.W2}\")\n",
        "\n",
        "        # Initialize biases (CHANGED)\n",
        "        self.b1 = np.array([[0.2, 0.05]])\n",
        "        print(f\"Initialized b1:\\n{self.b1}\")\n",
        "\n",
        "        self.b2 = np.array([[0.1]])\n",
        "        print(f\"Initialized b2:\\n{self.b2}\")\n",
        "\n",
        "        self.lr = learning_rate\n",
        "        print(f\"Learning Rate: {self.lr}\")\n",
        "\n",
        "    # Sigmoid activation function\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Derivative of sigmoid\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    # Forward propagation\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "\n",
        "        self.hidden_raw = np.dot(self.x, self.W1) + self.b1\n",
        "        self.hidden_output = self.sigmoid(self.hidden_raw)\n",
        "\n",
        "        self.output_raw = np.dot(self.hidden_output, self.W2) + self.b2\n",
        "        self.output = self.sigmoid(self.output_raw)\n",
        "\n",
        "        print(f\"Forward Pass Output:\\n{self.output}\")\n",
        "        return self.output\n",
        "\n",
        "    # Mean Squared Error loss\n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        loss = np.mean((y_true - y_pred) ** 2)\n",
        "        print(f\"Calculated Loss: {loss}\")\n",
        "        return loss\n",
        "\n",
        "    # Backward propagation\n",
        "    def backward(self, y_true):\n",
        "        # Output layer error\n",
        "        error_output = y_true - self.output\n",
        "        delta_output = error_output * self.sigmoid_derivative(self.output)\n",
        "\n",
        "        # Hidden layer error\n",
        "        error_hidden = np.dot(delta_output, self.W2.T)\n",
        "        delta_hidden = error_hidden * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.W2 += self.lr * np.dot(self.hidden_output.T, delta_output)\n",
        "        self.b2 += self.lr * delta_output\n",
        "\n",
        "        self.W1 += self.lr * np.dot(self.x.T, delta_hidden)\n",
        "        self.b1 += self.lr * delta_hidden\n",
        "\n",
        "    # Training step\n",
        "    def train(self, x, y):\n",
        "        y_pred = self.forward(x)\n",
        "        loss = self.compute_loss(y, y_pred)\n",
        "        self.backward(y)\n",
        "        print(f\"Training Step Loss: {loss}\")\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the neural network\n",
        "# Input size: 3 (e.g., 3 features)\n",
        "# Hidden size: 2\n",
        "# Output size: 1\n",
        "# Learning rate: 0.1 (default)\n",
        "neural_network = SimpleNeuralNetwork(input_size=3, hidden_size=2, output_size=1)\n",
        "\n",
        "# Define some sample input (x) and target output (y) data\n",
        "x = np.array([[0.1, 0.2, 0.3]])\n",
        "y = np.array([[0.8]])\n",
        "\n",
        "print(f\"\\nInput X:\\n{x}\")\n",
        "print(f\"Target Y:\\n{y}\")\n",
        "\n",
        "# Train the network for a few iterations\n",
        "print(\"\\n--- Starting Training ---\")\n",
        "for i in range(5): # Train for 5 epochs\n",
        "    loss = neural_network.train(x, y)\n",
        "    print(f\"Epoch {i+1}, Loss: {loss}\")\n",
        "\n",
        "print(\"\\n--- Training Complete ---\")\n",
        "\n",
        "# After training, you can make a prediction\n",
        "final_prediction = neural_network.forward(x)\n",
        "print(f\"\\nFinal Prediction after training:\\n{final_prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzyEOfIWlo8g",
        "outputId": "90f650a9-18f1-4002-e299-8b199dfe5b40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized W1:\n",
            "[[ 0.2 -0.4]\n",
            " [ 0.6  0.3]\n",
            " [-0.1  0.5]]\n",
            "Initialized W2:\n",
            "[[ 0.4]\n",
            " [-0.7]]\n",
            "Initialized b1:\n",
            "[[0.2  0.05]]\n",
            "Initialized b2:\n",
            "[[0.1]]\n",
            "Learning Rate: 0.2\n",
            "\n",
            "Input X:\n",
            "[[0.1 0.2 0.3]]\n",
            "Target Y:\n",
            "[[0.8]]\n",
            "\n",
            "--- Starting Training ---\n",
            "Forward Pass Output:\n",
            "[[0.48560614]]\n",
            "Calculated Loss: 0.09884350035595665\n",
            "Training Step Loss: 0.09884350035595665\n",
            "Epoch 1, Loss: 0.09884350035595665\n",
            "Forward Pass Output:\n",
            "[[0.49222059]]\n",
            "Calculated Loss: 0.09472816354918756\n",
            "Training Step Loss: 0.09472816354918756\n",
            "Epoch 2, Loss: 0.09472816354918756\n",
            "Forward Pass Output:\n",
            "[[0.49869977]]\n",
            "Calculated Loss: 0.09078183000142766\n",
            "Training Step Loss: 0.09078183000142766\n",
            "Epoch 3, Loss: 0.09078183000142766\n",
            "Forward Pass Output:\n",
            "[[0.50504216]]\n",
            "Calculated Loss: 0.08700012605621668\n",
            "Training Step Loss: 0.08700012605621668\n",
            "Epoch 4, Loss: 0.08700012605621668\n",
            "Forward Pass Output:\n",
            "[[0.51124683]]\n",
            "Calculated Loss: 0.08337839257793442\n",
            "Training Step Loss: 0.08337839257793442\n",
            "Epoch 5, Loss: 0.08337839257793442\n",
            "\n",
            "--- Training Complete ---\n",
            "Forward Pass Output:\n",
            "[[0.51731334]]\n",
            "\n",
            "Final Prediction after training:\n",
            "[[0.51731334]]\n"
          ]
        }
      ]
    }
  ]
}